{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(file_path, dataset):\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            dataset.append(json.loads(line))\n",
    "    return dataset\n",
    "\n",
    "def remove_columns(dataset, numeric_columns, categorical_columns):\n",
    "    for column in dataset.columns:\n",
    "        if column not in numeric_columns and column not in categorical_columns and column != 'label':\n",
    "            dataset.drop(column, axis=1, inplace=True)\n",
    "    return dataset\n",
    "\n",
    "def replace_null_values(dataset, numeric_columns, categorical_columns,numeric_imputer, categorical_imputer):\n",
    "    dataset[numeric_columns] = numeric_imputer.fit_transform(dataset[numeric_columns])\n",
    "    dataset[categorical_columns] = categorical_imputer.fit_transform(dataset[categorical_columns])\n",
    "    return dataset\n",
    "\n",
    "def normalize_numeric_columns(dataset, numeric_columns):\n",
    "    scaler = MinMaxScaler()\n",
    "    dataset[numeric_columns] = scaler.fit_transform(dataset[numeric_columns])\n",
    "    return dataset\n",
    "\n",
    "def top_n(dataset, categorical_columns):\n",
    "    top_val = 10\n",
    "    for col in categorical_columns:\n",
    "        value_counts = dataset[col].value_counts()\n",
    "        top_n_categories = value_counts.index[:top_val].tolist()\n",
    "        dataset[col] = dataset[col].where(dataset[col].isin(top_n_categories), other='Other')\n",
    "    return dataset\n",
    "\n",
    "def align_columns(train, test):\n",
    "   \n",
    "    missing_in_test = set(train.columns) - set(test.columns)\n",
    "    missing_in_train = set(test.columns) - set(train.columns) \n",
    "  \n",
    "    for col in missing_in_test: # aggiungi le colonne mancanti in test e riempi con False\n",
    "        test[col] = False\n",
    "    \n",
    "    for col in missing_in_train: # aggiungi le colonne mancanti in train e riempi con False\n",
    "        train[col] = False\n",
    "\n",
    "    # riordina le colonne in entrambi i dataset per avere la stessa struttura\n",
    "    train = train.reindex(sorted(train.columns), axis=1)\n",
    "    test = test.reindex(sorted(test.columns), axis=1)\n",
    "\n",
    "    return train, test\n",
    "\n",
    "def concat_datasets(df1, df2):\n",
    "    concatenated_df = pd.concat([df1, df2], ignore_index=True)\n",
    "    return concatenated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv('dataset_train.csv')\n",
    "df_test=pd.read_csv('dataset_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = [ 'auth_success','auth_attempts']\n",
    "categorical_columns=['dest_port', 'status_guess', 'version','kex_alg','mac_alg','host_key_alg', 'cipher_alg', 'client', 'direction']\n",
    "\n",
    "df_train=remove_columns(df_train, numeric_columns, categorical_columns)\n",
    "df_test=remove_columns(df_test, numeric_columns, categorical_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_imputer = SimpleImputer(strategy='mean')\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "df_train = replace_null_values(df_train, numeric_columns, categorical_columns, numeric_imputer, categorical_imputer)\n",
    "df_train = normalize_numeric_columns(df_train, numeric_columns)\n",
    "\n",
    "df_test = replace_null_values(df_test, numeric_columns, categorical_columns, numeric_imputer, categorical_imputer)\n",
    "df_test = normalize_numeric_columns(df_test, numeric_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(517898, 12)\n",
      "(132703, 12)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = top_n(df_train, categorical_columns)\n",
    "df_test = top_n(df_test, categorical_columns)\n",
    "\n",
    "# Codifica dei dati categorici con get_dummies di pandas per la codifica one-hot\n",
    "categorical_encoded = pd.get_dummies(df_train[categorical_columns])\n",
    "categorical_encoded_test = pd.get_dummies(df_test[categorical_columns])\n",
    "\n",
    "df_train = df_train.drop(columns=categorical_columns, axis=1) # Rimozione delle colonne categoriche originali\n",
    "df_train = pd.concat([df_train, categorical_encoded], axis=1) # Concatenazione delle nuove colonne codificate\n",
    "\n",
    "\n",
    "df_test = df_test.drop(columns=categorical_columns, axis=1)  # Rimozione delle colonne categoriche originali \n",
    "df_test = pd.concat([df_test, categorical_encoded_test], axis=1) # Concatenazione delle nuove colonne codificate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(517898, 64)\n",
      "(132703, 60)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, dataset_df_testtest = align_columns(df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(517898, 69)\n",
      "(132703, 69)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train:\n",
      "   A  B  C\n",
      "0  1  4  7\n",
      "1  2  5  8\n",
      "2  3  6  9\n",
      "\n",
      "test:\n",
      "    B   C   D\n",
      "0  10  13  16\n",
      "1  11  14  17\n",
      "2  12  15  18\n",
      "\n",
      "train modificato:\n",
      "   A  B  C      D\n",
      "0  1  4  7  False\n",
      "1  2  5  8  False\n",
      "2  3  6  9  False\n",
      "\n",
      "test modificato:\n",
      "       A   B   C   D\n",
      "0  False  10  13  16\n",
      "1  False  11  14  17\n",
      "2  False  12  15  18\n"
     ]
    }
   ],
   "source": [
    "#ESEMPIO FUNZIONAMENTO align_columns\n",
    "# Dataset di train (ha le colonne 'A', 'B', 'C')\n",
    "data_train = {'A': [1, 2, 3],\n",
    "              'B': [4, 5, 6],\n",
    "              'C': [7, 8, 9]}\n",
    "\n",
    "train = pd.DataFrame(data_train)\n",
    "\n",
    "# Dataset di test (ha le colonne 'B', 'C', 'D')\n",
    "data_test = {'B': [10, 11, 12],\n",
    "             'C': [13, 14, 15],\n",
    "             'D': [16, 17, 18]}\n",
    "\n",
    "test = pd.DataFrame(data_test)\n",
    "\n",
    "print(\"\\ntrain:\")\n",
    "print(train)\n",
    "print(\"\\ntest:\")\n",
    "print(test)\n",
    "\n",
    "train, test = align_columns(train, test)\n",
    "\n",
    "print(\"\\ntrain modificato:\")\n",
    "print(train)\n",
    "print(\"\\ntest modificato:\")\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_label_0 = df_train[df_train['label'] == 0]\n",
    "data_label_1 = df_train[df_train['label'] != 0]\n",
    "X_train=data_label_0.drop('label', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = df_test['label']\n",
    "X_test = df_test.drop('label', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "y_test = y_test.astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = pd.DataFrame(X_train)\n",
    "X_train_df.to_csv('X_train.csv', index=False)\n",
    "\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "X_test_df.to_csv('X_test.csv', index=False)\n",
    "\n",
    "y_test_df = pd.DataFrame(y_test)\n",
    "y_test_df.to_csv('y_test.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
