{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(file_path, dataset):\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            dataset.append(json.loads(line))\n",
    "    return dataset\n",
    "\n",
    "def remove_columns(dataset, numeric_columns, categorical_columns):\n",
    "    for column in dataset.columns:\n",
    "        if column not in numeric_columns and column not in categorical_columns and column != 'label':\n",
    "            dataset.drop(column, axis=1, inplace=True)\n",
    "    return dataset\n",
    "\n",
    "def replace_null_values(dataset, numeric_columns, categorical_columns,numeric_imputer, categorical_imputer):\n",
    "    dataset[numeric_columns] = numeric_imputer.fit_transform(dataset[numeric_columns])\n",
    "    dataset[categorical_columns] = categorical_imputer.fit_transform(dataset[categorical_columns])\n",
    "    return dataset\n",
    "\n",
    "def normalize_numeric_columns(dataset, numeric_columns):\n",
    "    scaler = MinMaxScaler()\n",
    "    dataset[numeric_columns] = scaler.fit_transform(dataset[numeric_columns])\n",
    "    return dataset\n",
    "\n",
    "def top_n(dataset, categorical_columns):\n",
    "    top_val = 10\n",
    "    for col in categorical_columns:\n",
    "        value_counts = dataset[col].value_counts()\n",
    "        top_n_categories = value_counts.index[:top_val].tolist()\n",
    "        dataset[col] = dataset[col].where(dataset[col].isin(top_n_categories), other='Other')\n",
    "    return dataset\n",
    "\n",
    "def align_columns(train, test):\n",
    "   \n",
    "    missing_in_test = set(train.columns) - set(test.columns)\n",
    "    missing_in_train = set(test.columns) - set(train.columns) \n",
    "  \n",
    "    for col in missing_in_test: # aggiungi le colonne mancanti in test e riempi con False\n",
    "        test[col] = False\n",
    "    \n",
    "    for col in missing_in_train: # aggiungi le colonne mancanti in train e riempi con False\n",
    "        train[col] = False\n",
    "\n",
    "    # riordina le colonne in entrambi i dataset per avere la stessa struttura\n",
    "    train = train.reindex(sorted(train.columns), axis=1)\n",
    "    test = test.reindex(sorted(test.columns), axis=1)\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv('dati/dataset_train.csv')\n",
    "dataset_test=pd.read_csv('dati/dataset_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features\n",
    "\n",
    "#dest_ip: L'indirizzo IP di destinazione\n",
    "#\n",
    "#epochdate: Un timestamp in formato epoch\n",
    "#\n",
    "#source_ip: L'indirizzo IP di origine\n",
    "#\n",
    "#@host: L'host che ha registrato l'evento\n",
    "#\n",
    "#@timestamp: La data e l'ora in cui è stato registrato l'evento (ad esempio, \"2021-10-04T00:00:00.000Z\")\n",
    "#\n",
    "#dest_port: La porta di destinazione utilizzata per la connessione SSH. Tipicamente è la porta 22 (default per SSH), ma potrebbe essere personalizzata.\n",
    "#\n",
    "#status_guess: Un'indicazione dello stato della connessione (ad esempio, successo o fallimento)\n",
    "#\n",
    "#uid: Un identificatore univoco per la sessione o per la connessione SSH\n",
    "#\n",
    "#@type: Il tipo di evento o di log\n",
    "# \n",
    "#source_port: La porta di origine utilizzata per la connessione\n",
    "#\n",
    "#host_key_alg: L'algoritmo utilizzato per la chiave host del server SSH\n",
    "#\n",
    "#host_key: La chiave pubblica del server SSH. Viene utilizzato dal client per verificare l'autenticità del server durante la negoziazione della connessione\n",
    "#\n",
    "#server: Nome o identificativo del server che gestisce la connessione SSH.\n",
    "#\n",
    "#version: La versione del protocollo SSH utilizzata per la connessione \n",
    "#\n",
    "#remote_location_latitude: La latitudine della posizione geografica dell'indirizzo IP di origine\n",
    "# \n",
    "#compression_alg: L'algoritmo di compressione utilizzato (se presente) nella sessione SSH per ridurre il traffico trasmesso\n",
    "#\n",
    "#kex_alg: L'algoritmo di scambio delle chiavi utilizzato nella negoziazione della sessione SSH\n",
    "#\n",
    "#remote_location_longitude: La longitudine della posizione geografica dell'indirizzo IP di origine\n",
    "#\n",
    "#auth_attempts: Il numero di tentativi di autenticazione fatti dal client per stabilire la connessione SSH\n",
    "#\n",
    "#remote_location_country_code: Il codice del paese di origine dell'indirizzo IP\n",
    "#\n",
    "#cipher_alg: L'algoritmo di cifratura utilizzato per la sessione SSH\n",
    "#\n",
    "#mac_alg: L'algoritmo per il Message Authentication Code (MAC), utilizzato per verificare l'integrità dei dati nella sessione SS\n",
    "#\n",
    "#auth_success: Un booleano che indica se il tentativo di autenticazione è stato un successo o meno\n",
    "#\n",
    "#direction: La direzione della connessione SSH. Può indicare se la connessione è stata \"inbound\" (in arrivo verso il server) o \"outbound\" (in uscita dal server)\n",
    "#\n",
    "#client: Il client SSH utilizzato per stabilire la connessione\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = [ 'auth_success','auth_attempts']\n",
    "categorical_columns=['dest_port', 'status_guess', 'version','kex_alg','mac_alg','host_key_alg', 'cipher_alg', 'client', 'direction']\n",
    "\n",
    "dataset=remove_columns(dataset, numeric_columns, categorical_columns)\n",
    "dataset_test=remove_columns(dataset_test, numeric_columns, categorical_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_imputer = SimpleImputer(strategy='mean')\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "dataset = replace_null_values(dataset, numeric_columns, categorical_columns, numeric_imputer, categorical_imputer)\n",
    "dataset = normalize_numeric_columns(dataset, numeric_columns)\n",
    "\n",
    "dataset_test = replace_null_values(dataset_test, numeric_columns, categorical_columns, numeric_imputer, categorical_imputer)\n",
    "dataset_test = normalize_numeric_columns(dataset_test, numeric_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(433929, 12)\n",
      "(132703, 12)\n"
     ]
    }
   ],
   "source": [
    "print(dataset.shape)\n",
    "print(dataset_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = top_n(dataset, categorical_columns)\n",
    "dataset_test = top_n(dataset_test, categorical_columns)\n",
    "\n",
    "# Codifica dei dati categorici con get_dummies di pandas per la codifica one-hot\n",
    "categorical_encoded = pd.get_dummies(dataset[categorical_columns])\n",
    "categorical_encoded_test = pd.get_dummies(dataset_test[categorical_columns])\n",
    "\n",
    "dataset = dataset.drop(columns=categorical_columns, axis=1) # Rimozione delle colonne categoriche originali\n",
    "dataset = pd.concat([dataset, categorical_encoded], axis=1) # Concatenazione delle nuove colonne codificate\n",
    "\n",
    "\n",
    "dataset_test = dataset_test.drop(columns=categorical_columns, axis=1)  # Rimozione delle colonne categoriche originali \n",
    "dataset_test = pd.concat([dataset_test, categorical_encoded_test], axis=1) # Concatenazione delle nuove colonne codificate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(433929, 64)\n",
      "(132703, 60)\n"
     ]
    }
   ],
   "source": [
    "print(dataset.shape)\n",
    "print(dataset_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, dataset_test = align_columns(dataset, dataset_test)\n",
    "\n",
    "print(dataset_test.head())\n",
    "print(dataset.head())\n",
    "print(dataset.columns.to_list())\n",
    "print(dataset_test.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(433929, 68)\n",
      "(132703, 68)\n"
     ]
    }
   ],
   "source": [
    "print(dataset.shape)\n",
    "print(dataset_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train:\n",
      "   A  B  C\n",
      "0  1  4  7\n",
      "1  2  5  8\n",
      "2  3  6  9\n",
      "\n",
      "test:\n",
      "    B   C   D\n",
      "0  10  13  16\n",
      "1  11  14  17\n",
      "2  12  15  18\n",
      "\n",
      "train modificato:\n",
      "   A  B  C      D\n",
      "0  1  4  7  False\n",
      "1  2  5  8  False\n",
      "2  3  6  9  False\n",
      "\n",
      "test modificato:\n",
      "       A   B   C   D\n",
      "0  False  10  13  16\n",
      "1  False  11  14  17\n",
      "2  False  12  15  18\n"
     ]
    }
   ],
   "source": [
    "#ESEMPIO FUNZIONAMENTO align_columns\n",
    "# Dataset di train (ha le colonne 'A', 'B', 'C')\n",
    "data_train = {'A': [1, 2, 3],\n",
    "              'B': [4, 5, 6],\n",
    "              'C': [7, 8, 9]}\n",
    "\n",
    "train = pd.DataFrame(data_train)\n",
    "\n",
    "# Dataset di test (ha le colonne 'B', 'C', 'D')\n",
    "data_test = {'B': [10, 11, 12],\n",
    "             'C': [13, 14, 15],\n",
    "             'D': [16, 17, 18]}\n",
    "\n",
    "test = pd.DataFrame(data_test)\n",
    "\n",
    "print(\"\\ntrain:\")\n",
    "print(train)\n",
    "print(\"\\ntest:\")\n",
    "print(test)\n",
    "\n",
    "train, test = align_columns(train, test)\n",
    "\n",
    "print(\"\\ntrain modificato:\")\n",
    "print(train)\n",
    "print(\"\\ntest modificato:\")\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nAnteprima dopo la codifica one-hot:\")\n",
    "print(dataset.head())\n",
    "print(dataset_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_label_0 = dataset[dataset['label'] == 0]\n",
    "data_label_1 = dataset[dataset['label'] != 0]\n",
    "X_train=data_label_0.drop('label', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = dataset_test['label']\n",
    "X_test = dataset_test.drop('label', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "y_test = y_test.astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = pd.DataFrame(X_train)\n",
    "X_train_df.to_csv('dati/X_train.csv', index=False)\n",
    "print(X_train_df.head())\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "X_test_df.to_csv('dati/X_test.csv', index=False)\n",
    "print(X_test_df.head())\n",
    "y_test_df = pd.DataFrame(y_test)\n",
    "y_test_df.to_csv('dati/y_test.csv', index=False)\n",
    "print(y_test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.columns.to_list())\n",
    "print(X_train.columns.to_list())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
