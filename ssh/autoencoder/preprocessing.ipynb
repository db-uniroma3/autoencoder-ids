{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(file_path):\n",
    "    dataset= pd.read_csv(file_path)\n",
    "    return dataset\n",
    "\n",
    "def define_columns_types():\n",
    "    numeric_columns = [ 'auth_success','auth_attempts']\n",
    "    categorical_columns=['dest_port', 'status_guess', 'version','kex_alg','mac_alg','host_key_alg', 'cipher_alg', 'client', 'direction']\n",
    "    return numeric_columns, categorical_columns\n",
    "\n",
    "def remove_columns(dataset, numeric_columns, categorical_columns):\n",
    "    for column in dataset.columns:\n",
    "        if column not in numeric_columns and column not in categorical_columns and column != 'label':\n",
    "            dataset.drop(column, axis=1, inplace=True)\n",
    "    return dataset\n",
    "\n",
    "def replace_null_values(dataset, numeric_columns, categorical_columns):\n",
    "    numeric_imputer = SimpleImputer(strategy='mean')\n",
    "    categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "    dataset[numeric_columns] = numeric_imputer.fit_transform(dataset[numeric_columns])\n",
    "    dataset[categorical_columns] = categorical_imputer.fit_transform(dataset[categorical_columns])\n",
    "    return dataset\n",
    "\n",
    "def normalize_numeric_columns(dataset, numeric_columns):\n",
    "    scaler = MinMaxScaler()\n",
    "    dataset[numeric_columns] = scaler.fit_transform(dataset[numeric_columns])\n",
    "    return dataset\n",
    "\n",
    "def top_n(dataset, categorical_columns):\n",
    "    top_val = 10\n",
    "    for col in categorical_columns:\n",
    "        value_counts = dataset[col].value_counts()\n",
    "        top_n_categories = value_counts.index[:top_val].tolist()\n",
    "        dataset[col] = dataset[col].where(dataset[col].isin(top_n_categories), other='Other')\n",
    "    return dataset\n",
    "\n",
    "def categorical_data_encoding(dataset, categorical_columns):\n",
    "    encoded_dataset = pd.get_dummies(dataset[categorical_columns])\n",
    "    dataset = dataset.drop(columns=categorical_columns, axis=1)\n",
    "    dataset = pd.concat([dataset, encoded_dataset], axis=1)\n",
    "    return dataset\n",
    "\n",
    "def align_columns(train, test):\n",
    "   \n",
    "    missing_in_test = set(train.columns) - set(test.columns)\n",
    "    missing_in_train = set(test.columns) - set(train.columns) \n",
    "  \n",
    "    for col in missing_in_test: # aggiungi le colonne mancanti in test e riempi con False\n",
    "        test[col] = False\n",
    "    \n",
    "    for col in missing_in_train: # aggiungi le colonne mancanti in train e riempi con False\n",
    "        train[col] = False\n",
    "\n",
    "    # riordina le colonne in entrambi i dataset per avere la stessa struttura\n",
    "    train = train.reindex(sorted(train.columns), axis=1)\n",
    "    test = test.reindex(sorted(test.columns), axis=1)\n",
    "\n",
    "    return train, test\n",
    "\n",
    "def save_test(df, output_prefix):\n",
    "    \n",
    "    # Separazione delle feature (X) e delle label (y)\n",
    "    y = df['label']\n",
    "    x = df.drop('label', axis=1)\n",
    "\n",
    "    # Conversione dei dati in float32\n",
    "    x = x.astype('float32')\n",
    "    y = y.astype('float32')\n",
    "\n",
    "    # Salvataggio dei dati in file CSV\n",
    "    x.to_csv(f'X_{output_prefix}.csv', index=False)\n",
    "    y.to_csv(f'y_{output_prefix}.csv', index=False)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "def save_train(df, output_prefix):\n",
    "    data_label_0 = df[df['label'] == 0]\n",
    "\n",
    "    x=data_label_0.drop('label', axis=1)\n",
    "    \n",
    "    # Conversione dei dati in float32\n",
    "    x = x.astype('float32')\n",
    "\n",
    "    # Salvataggio dei dati in file CSV\n",
    "    x.to_csv(f'X_{output_prefix}.csv', index=False)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Eseguire tutte le funzioni di preprocessing nell'ordine corretto:\n",
    "    1. Caricare il dataset ->  read_dataset(file_path)\n",
    "    2. Definire i tipi di colonne -> define_columns_types()\n",
    "    3. Rimuovere le colonne non necessarie -> remove_columns(dataset, numeric_columns, categorical_columns)\n",
    "    4. Modificare la colonna 'host' -> modify_host_column(dataset)\n",
    "    5. Sostituire i valori nulli -> replace_null_values(dataset, numeric_columns, categorical_columns)\n",
    "    6. Normalizzare le colonne numeriche -> normalize_numeric_columns(dataset, numeric_columns)\n",
    "    7. Sostituire i valori delle colonne categoriche con i top n valori -> top_n(dataset, categorical_columns)\n",
    "    8. Codificare le colonne categoriche -> categorical_data_encoding(dataset, categorical_columns)\n",
    "    9. Allineare le colonne tra train e test -> align_columns(train, test)\n",
    "    10. Salvare i dati di train -> save_train(df, output_prefix)\n",
    "    11. Salvare i dati di test -> save_test(df, output_prefix)\n",
    "\n",
    "    l'ouput Ã¨ il dataset X, che contiene solo le feature, e y, che contiene solo le label\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "    Esempio di utilizzo delle funzioni di preprocessing con un dataset di train e un dataset di test:\n",
    "    \n",
    "    df_train=read_dataset('train_ssh_row.csv')\n",
    "    df_test=read_dataset('test_ssh_row.csv')\n",
    "\n",
    "    numeric_columns, categorical_columns=define_columns_types()\n",
    "\n",
    "    df_train=remove_columns(df_train, numeric_columns, categorical_columns)\n",
    "    df_train=modify_host_column(df_train)\n",
    "    df_train=replace_null_values(df_train, numeric_columns, categorical_columns)\n",
    "    df_train=normalize_numeric_columns(df_train, numeric_columns)\n",
    "    df_train=top_n(df_train, categorical_columns)\n",
    "    df_train=categorical_data_encoding(df_train, categorical_columns)\n",
    "\n",
    "    df_test=remove_columns(df_test, numeric_columns, categorical_columns)\n",
    "    df_test=modify_host_column(df_test)\n",
    "    df_test=replace_null_values(df_test, numeric_columns, categorical_columns)\n",
    "    df_test=normalize_numeric_columns(df_test, numeric_columns)\n",
    "    df_test=top_n(df_test, categorical_columns)\n",
    "    df_test=categorical_data_encoding(df_test, categorical_columns)\n",
    "\n",
    "    df_train, df_test=align_columns(df_train, df_test)\n",
    "\n",
    "    save_train(df_train, 'train')\n",
    "    save_test(df_test, 'test')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=read_dataset('train_ssh_row.csv')\n",
    "df_test=read_dataset('test_ssh_row.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns, categorical_columns=define_columns_types()\n",
    "\n",
    "df_train=remove_columns(df_train, numeric_columns, categorical_columns)\n",
    "df_test=remove_columns(df_test, numeric_columns, categorical_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = replace_null_values(df_train, numeric_columns, categorical_columns)\n",
    "df_train = normalize_numeric_columns(df_train, numeric_columns)\n",
    "\n",
    "df_test = replace_null_values(df_test, numeric_columns, categorical_columns)\n",
    "df_test = normalize_numeric_columns(df_test, numeric_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = top_n(df_train, categorical_columns)\n",
    "df_test = top_n(df_test, categorical_columns)\n",
    "\n",
    "df_train = categorical_data_encoding(df_train, categorical_columns)\n",
    "df_test = categorical_data_encoding(df_test, categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = align_columns(df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_train(df_train, 'train')\n",
    "save_test(df_test, 'test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
