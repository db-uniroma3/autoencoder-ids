{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_ip_address(value):# Funzione per verificare se un valore è un indirizzo IP\n",
    "    ip_pattern = re.compile(r'^(\\d{1,3}\\.){3}\\d{1,3}$')\n",
    "    return bool(ip_pattern.match(value))\n",
    "\n",
    "def modify_host_column(dataset):# Modifica i valori della colonna 'host' in 1 se è un indirizzo IP, 0 altrimenti\n",
    "    val=dataset['host'].astype(str)\n",
    "    dataset['host'] = val.apply(lambda x: 1 if is_ip_address(x) else 0)\n",
    "    return dataset\n",
    "\n",
    "def remove_columns(dataset, numeric_columns, categorical_columns):\n",
    "    for column in dataset.columns:\n",
    "        if column not in numeric_columns and column not in categorical_columns and column != 'label' and column != '@timestamp':\n",
    "            dataset.drop(column, axis=1, inplace=True)\n",
    "    return dataset\n",
    "\n",
    "def replace_null_values(dataset, numeric_columns, categorical_columns,numeric_imputer, categorical_imputer):\n",
    "    dataset[numeric_columns] = numeric_imputer.fit_transform(dataset[numeric_columns])\n",
    "    dataset[categorical_columns] = categorical_imputer.fit_transform(dataset[categorical_columns])\n",
    "    return dataset\n",
    "\n",
    "def normalize_numeric_columns(dataset, numeric_columns):\n",
    "    scaler = MinMaxScaler()\n",
    "    dataset[numeric_columns] = scaler.fit_transform(dataset[numeric_columns])\n",
    "    return dataset\n",
    "\n",
    "def top_n(dataset, categorical_columns):\n",
    "    top_val = 10\n",
    "    for col in categorical_columns:\n",
    "        if col!= 'status_code': #considero tutti i possibili status_code\n",
    "            value_counts = dataset[col].value_counts()\n",
    "            top_n_categories = value_counts.index[:top_val].tolist()\n",
    "            dataset[col] = dataset[col].where(dataset[col].isin(top_n_categories), other='Other')\n",
    "    return dataset\n",
    "\n",
    "def align_columns(train, test): #funzione per dare lo stesso scheletro ai dataset di train e test\n",
    "   \n",
    "    missing_in_test = set(train.columns) - set(test.columns)\n",
    "    missing_in_train = set(test.columns) - set(train.columns) \n",
    "  \n",
    "    for col in missing_in_test: # aggiungi le colonne mancanti in test e riempi con False\n",
    "        test[col] = False\n",
    "    \n",
    "    for col in missing_in_train: # aggiungi le colonne mancanti in train e riempi con False\n",
    "        train[col] = False\n",
    "\n",
    "    # riordina le colonne in entrambi i dataset per avere la stessa struttura\n",
    "    train = train.reindex(sorted(train.columns), axis=1)\n",
    "    test = test.reindex(sorted(test.columns), axis=1)\n",
    "\n",
    "    return train, test\n",
    "\n",
    "def add_padding(max_len,data):\n",
    "    data=pad_sequences(data, maxlen=max_len, padding='post', value=0.0, dtype='float32')\n",
    "    return data\n",
    "\n",
    "def create_window(df, window_size_records, label_column): \n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    df = df.sort_values('@timestamp')\n",
    "\n",
    "    # Scorre il dataframe creando finestre di dimensione fissa\n",
    "    for i in range(0, len(df), window_size_records):\n",
    "        window_records = df.iloc[i:i + window_size_records]\n",
    "        \n",
    "        if not window_records.empty:\n",
    "\n",
    "            window_records = window_records.drop(columns=['@timestamp'])\n",
    "            window_records=window_records.astype(float)\n",
    "            \n",
    "            labels.append(window_records[label_column].values)\n",
    "\n",
    "            window_records = window_records.drop(columns=[label_column])\n",
    "            \n",
    "            data.append(window_records)\n",
    "\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv('dataset.csv')\n",
    "dataset_test=pd.read_csv('dataset_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = ['request_body_len', 'trans_depth', 'response_body_len','host']\n",
    "categorical_columns=['dest_port', 'method', 'version', 'status_code', 'response_content_type', 'request_content_type']\n",
    "\n",
    "dataset=remove_columns(dataset, numeric_columns, categorical_columns)\n",
    "dataset=modify_host_column(dataset)\n",
    "\n",
    "dataset_test=remove_columns(dataset_test, numeric_columns, categorical_columns)\n",
    "dataset_test=modify_host_column(dataset_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_imputer = SimpleImputer(strategy='mean')\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "dataset = replace_null_values(dataset, numeric_columns, categorical_columns, numeric_imputer, categorical_imputer)\n",
    "dataset = normalize_numeric_columns(dataset, numeric_columns)\n",
    "\n",
    "dataset_test = replace_null_values(dataset_test, numeric_columns, categorical_columns, numeric_imputer, categorical_imputer)\n",
    "dataset_test = normalize_numeric_columns(dataset_test, numeric_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = top_n(dataset, categorical_columns)\n",
    "dataset_test = top_n(dataset_test, categorical_columns)\n",
    "\n",
    "# Codifica one-hot dei dai categorici\n",
    "categorical_encoded = pd.get_dummies(dataset[categorical_columns])\n",
    "categorical_encoded_test = pd.get_dummies(dataset_test[categorical_columns])\n",
    "\n",
    "dataset = dataset.drop(columns=categorical_columns, axis=1) # Rimozione delle colonne categoriche originali\n",
    "dataset = pd.concat([dataset, categorical_encoded], axis=1) # Concatenazione delle nuove colonne codificate\n",
    "\n",
    "\n",
    "dataset_test = dataset_test.drop(columns=categorical_columns, axis=1)  # Rimozione delle colonne categoriche originali \n",
    "dataset_test = pd.concat([dataset_test, categorical_encoded_test], axis=1) # Concatenazione delle nuove colonne codificate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, dataset_test = align_columns(dataset, dataset_test)\n",
    "\n",
    "print(dataset_test.head())\n",
    "print(dataset.head())\n",
    "print(dataset.columns.to_list())\n",
    "print(dataset_test.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train:\n",
      "   A  B  C\n",
      "0  1  4  7\n",
      "1  2  5  8\n",
      "2  3  6  9\n",
      "\n",
      "test:\n",
      "    B   C   D\n",
      "0  10  13  16\n",
      "1  11  14  17\n",
      "2  12  15  18\n",
      "\n",
      "train modificato:\n",
      "   A  B  C      D\n",
      "0  1  4  7  False\n",
      "1  2  5  8  False\n",
      "2  3  6  9  False\n",
      "\n",
      "test modificato:\n",
      "       A   B   C   D\n",
      "0  False  10  13  16\n",
      "1  False  11  14  17\n",
      "2  False  12  15  18\n"
     ]
    }
   ],
   "source": [
    "#ESEMPIO FUNZIONAMENTO align_columns\n",
    "# Dataset di train (ha le colonne 'A', 'B', 'C')\n",
    "data_train = {'A': [1, 2, 3],\n",
    "              'B': [4, 5, 6],\n",
    "              'C': [7, 8, 9]}\n",
    "\n",
    "train = pd.DataFrame(data_train)\n",
    "\n",
    "# Dataset di test (ha le colonne 'B', 'C', 'D')\n",
    "data_test = {'B': [10, 11, 12],\n",
    "             'C': [13, 14, 15],\n",
    "             'D': [16, 17, 18]}\n",
    "\n",
    "test = pd.DataFrame(data_test)\n",
    "\n",
    "print(\"\\ntrain:\")\n",
    "print(train)\n",
    "print(\"\\ntest:\")\n",
    "print(test)\n",
    "\n",
    "train, test = align_columns(train, test)\n",
    "\n",
    "print(\"\\ntrain modificato:\")\n",
    "print(train)\n",
    "print(\"\\ntest modificato:\")\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_label_0 = dataset[dataset['label'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size_seconds = 600\n",
    "label_column = 'label'\n",
    "\n",
    "X_train, y_train = create_window(data_label_0, window_size_seconds, label_column)\n",
    "X_test, y_test= create_window(dataset_test, window_size_seconds, label_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_padded=add_padding(window_size_seconds,X_train)\n",
    "X_test_padded=add_padding(window_size_seconds,X_test)\n",
    "y_test_padded=add_padding(window_size_seconds,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(y_test_padded, 'y_test.joblib')\n",
    "dump(X_test_padded, 'X_test.joblib')\n",
    "dump(X_train_padded, 'X_train.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
